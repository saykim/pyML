{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seaborn_loaddata.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saykim/pyML/blob/master/seaborn_loaddata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceYOD7Y089rj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLY5t41l-gEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "diamond = sns.load_dataset('diamonds')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC8Il_n4-mPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "bb338de7-119c-464e-e6e6-693633a17e88"
      },
      "source": [
        "diamond.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>cut</th>\n",
              "      <th>color</th>\n",
              "      <th>clarity</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>price</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.23</td>\n",
              "      <td>Ideal</td>\n",
              "      <td>E</td>\n",
              "      <td>SI2</td>\n",
              "      <td>61.5</td>\n",
              "      <td>55.0</td>\n",
              "      <td>326</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.98</td>\n",
              "      <td>2.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>Premium</td>\n",
              "      <td>E</td>\n",
              "      <td>SI1</td>\n",
              "      <td>59.8</td>\n",
              "      <td>61.0</td>\n",
              "      <td>326</td>\n",
              "      <td>3.89</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.23</td>\n",
              "      <td>Good</td>\n",
              "      <td>E</td>\n",
              "      <td>VS1</td>\n",
              "      <td>56.9</td>\n",
              "      <td>65.0</td>\n",
              "      <td>327</td>\n",
              "      <td>4.05</td>\n",
              "      <td>4.07</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.29</td>\n",
              "      <td>Premium</td>\n",
              "      <td>I</td>\n",
              "      <td>VS2</td>\n",
              "      <td>62.4</td>\n",
              "      <td>58.0</td>\n",
              "      <td>334</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.23</td>\n",
              "      <td>2.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.31</td>\n",
              "      <td>Good</td>\n",
              "      <td>J</td>\n",
              "      <td>SI2</td>\n",
              "      <td>63.3</td>\n",
              "      <td>58.0</td>\n",
              "      <td>335</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.35</td>\n",
              "      <td>2.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   carat      cut color clarity  depth  table  price     x     y     z\n",
              "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
              "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
              "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
              "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
              "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_dMqN-v-rvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "bf42280f-a393-4f5e-eb4a-89411191f17e"
      },
      "source": [
        "diamond.tail()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>cut</th>\n",
              "      <th>color</th>\n",
              "      <th>clarity</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>price</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53935</th>\n",
              "      <td>0.72</td>\n",
              "      <td>Ideal</td>\n",
              "      <td>D</td>\n",
              "      <td>SI1</td>\n",
              "      <td>60.8</td>\n",
              "      <td>57.0</td>\n",
              "      <td>2757</td>\n",
              "      <td>5.75</td>\n",
              "      <td>5.76</td>\n",
              "      <td>3.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53936</th>\n",
              "      <td>0.72</td>\n",
              "      <td>Good</td>\n",
              "      <td>D</td>\n",
              "      <td>SI1</td>\n",
              "      <td>63.1</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2757</td>\n",
              "      <td>5.69</td>\n",
              "      <td>5.75</td>\n",
              "      <td>3.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53937</th>\n",
              "      <td>0.70</td>\n",
              "      <td>Very Good</td>\n",
              "      <td>D</td>\n",
              "      <td>SI1</td>\n",
              "      <td>62.8</td>\n",
              "      <td>60.0</td>\n",
              "      <td>2757</td>\n",
              "      <td>5.66</td>\n",
              "      <td>5.68</td>\n",
              "      <td>3.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53938</th>\n",
              "      <td>0.86</td>\n",
              "      <td>Premium</td>\n",
              "      <td>H</td>\n",
              "      <td>SI2</td>\n",
              "      <td>61.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>2757</td>\n",
              "      <td>6.15</td>\n",
              "      <td>6.12</td>\n",
              "      <td>3.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53939</th>\n",
              "      <td>0.75</td>\n",
              "      <td>Ideal</td>\n",
              "      <td>D</td>\n",
              "      <td>SI2</td>\n",
              "      <td>62.2</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2757</td>\n",
              "      <td>5.83</td>\n",
              "      <td>5.87</td>\n",
              "      <td>3.64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       carat        cut color clarity  depth  table  price     x     y     z\n",
              "53935   0.72      Ideal     D     SI1   60.8   57.0   2757  5.75  5.76  3.50\n",
              "53936   0.72       Good     D     SI1   63.1   55.0   2757  5.69  5.75  3.61\n",
              "53937   0.70  Very Good     D     SI1   62.8   60.0   2757  5.66  5.68  3.56\n",
              "53938   0.86    Premium     H     SI2   61.0   58.0   2757  6.15  6.12  3.74\n",
              "53939   0.75      Ideal     D     SI2   62.2   55.0   2757  5.83  5.87  3.64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EZI3-oP-5xE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = diamond.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFxbmc7cElNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset[:,:6]\n",
        "Y_obj = dataset[:,6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNTfImcZEuZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e = LabelEncoder()\n",
        "y1 = e.fit_transform(Y_obj)\n",
        "Y=pd.get_dummies(y1).values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEJT-AlaE59t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e = LabelEncoder()\n",
        "diamond['cut'] = e.fit_transform(diamond['cut'])\n",
        "diamond['clarity'] = e.fit_transform(diamond['clarity'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJQgVr2QFWBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "diamond['color'] = e.fit_transform(diamond['color'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_epYlA9hFNut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "b87010fb-c53c-44ec-d915-283d594271cf"
      },
      "source": [
        "diamond.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>cut</th>\n",
              "      <th>color</th>\n",
              "      <th>clarity</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>price</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.23</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>61.5</td>\n",
              "      <td>55.0</td>\n",
              "      <td>326</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.98</td>\n",
              "      <td>2.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>59.8</td>\n",
              "      <td>61.0</td>\n",
              "      <td>326</td>\n",
              "      <td>3.89</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>56.9</td>\n",
              "      <td>65.0</td>\n",
              "      <td>327</td>\n",
              "      <td>4.05</td>\n",
              "      <td>4.07</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.29</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>62.4</td>\n",
              "      <td>58.0</td>\n",
              "      <td>334</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.23</td>\n",
              "      <td>2.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.31</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>63.3</td>\n",
              "      <td>58.0</td>\n",
              "      <td>335</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.35</td>\n",
              "      <td>2.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   carat  cut  color  clarity  depth  table  price     x     y     z\n",
              "0   0.23    2      1        3   61.5   55.0    326  3.95  3.98  2.43\n",
              "1   0.21    3      1        2   59.8   61.0    326  3.89  3.84  2.31\n",
              "2   0.23    1      1        4   56.9   65.0    327  4.05  4.07  2.31\n",
              "3   0.29    3      5        5   62.4   58.0    334  4.20  4.23  2.63\n",
              "4   0.31    1      6        3   63.3   58.0    335  4.34  4.35  2.75"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQBdtE5rWygc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import  train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_obj, test_size=0.3, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agT8yuLMFQDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df7d46a3-117f-495c-ee15-92a762cb2983"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=6, activation='relu'))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(X_train, Y_train, epochs=200, batch_size=10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "37758/37758 [==============================] - 11s 279us/step - loss: 31651357.1906\n",
            "Epoch 2/200\n",
            "37758/37758 [==============================] - 10s 270us/step - loss: 31622763.5416\n",
            "Epoch 3/200\n",
            "37758/37758 [==============================] - 11s 282us/step - loss: 31594386.7500\n",
            "Epoch 4/200\n",
            "37758/37758 [==============================] - 10s 276us/step - loss: 31566056.5207\n",
            "Epoch 5/200\n",
            "37758/37758 [==============================] - 10s 270us/step - loss: 31537731.4400\n",
            "Epoch 6/200\n",
            "37758/37758 [==============================] - 10s 270us/step - loss: 31509525.4791\n",
            "Epoch 7/200\n",
            "37758/37758 [==============================] - 10s 271us/step - loss: 31481307.3542\n",
            "Epoch 8/200\n",
            "37758/37758 [==============================] - 10s 264us/step - loss: 31453145.5753\n",
            "Epoch 9/200\n",
            "37758/37758 [==============================] - 10s 264us/step - loss: 31424924.3412\n",
            "Epoch 10/200\n",
            "37758/37758 [==============================] - 10s 265us/step - loss: 31396785.6608\n",
            "Epoch 11/200\n",
            "37758/37758 [==============================] - 10s 262us/step - loss: 31368679.4541\n",
            "Epoch 12/200\n",
            "37758/37758 [==============================] - 10s 263us/step - loss: 31340598.5134\n",
            "Epoch 13/200\n",
            "37758/37758 [==============================] - 10s 265us/step - loss: 31312538.0142\n",
            "Epoch 14/200\n",
            "37758/37758 [==============================] - 10s 268us/step - loss: 31284491.7310\n",
            "Epoch 15/200\n",
            "37758/37758 [==============================] - 10s 265us/step - loss: 31256449.2855\n",
            "Epoch 16/200\n",
            "37758/37758 [==============================] - 10s 264us/step - loss: 31228513.6336\n",
            "Epoch 17/200\n",
            "37758/37758 [==============================] - 10s 266us/step - loss: 31200597.2007\n",
            "Epoch 18/200\n",
            "37758/37758 [==============================] - 10s 264us/step - loss: 31172658.6876\n",
            "Epoch 19/200\n",
            "37758/37758 [==============================] - 10s 263us/step - loss: 31144722.4757\n",
            "Epoch 20/200\n",
            "37758/37758 [==============================] - 10s 264us/step - loss: 31116787.2839\n",
            "Epoch 21/200\n",
            "37758/37758 [==============================] - 10s 265us/step - loss: 31088980.1161\n",
            "Epoch 22/200\n",
            "37758/37758 [==============================] - 10s 268us/step - loss: 31061127.7031\n",
            "Epoch 23/200\n",
            "37758/37758 [==============================] - 10s 265us/step - loss: 31033341.6764\n",
            "Epoch 24/200\n",
            "37758/37758 [==============================] - 10s 264us/step - loss: 31005515.9153\n",
            "Epoch 25/200\n",
            "37758/37758 [==============================] - 10s 263us/step - loss: 30977737.8761\n",
            "Epoch 26/200\n",
            "37758/37758 [==============================] - 10s 263us/step - loss: 30949971.7206\n",
            "Epoch 27/200\n",
            "37758/37758 [==============================] - 10s 263us/step - loss: 30922336.4752\n",
            "Epoch 28/200\n",
            "37758/37758 [==============================] - 10s 263us/step - loss: 30894667.3669\n",
            "Epoch 29/200\n",
            "37758/37758 [==============================] - 10s 263us/step - loss: 30867134.6025\n",
            "Epoch 30/200\n",
            "37758/37758 [==============================] - 10s 262us/step - loss: 30839573.1397\n",
            "Epoch 31/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 30811970.2679\n",
            "Epoch 32/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 30784420.9542\n",
            "Epoch 33/200\n",
            "37758/37758 [==============================] - 10s 262us/step - loss: 30756991.8123\n",
            "Epoch 34/200\n",
            "37758/37758 [==============================] - 10s 274us/step - loss: 30729514.8367\n",
            "Epoch 35/200\n",
            "37758/37758 [==============================] - 10s 267us/step - loss: 30702066.1101\n",
            "Epoch 36/200\n",
            "37758/37758 [==============================] - 10s 263us/step - loss: 30674666.4956\n",
            "Epoch 37/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 30647298.5559\n",
            "Epoch 38/200\n",
            "37758/37758 [==============================] - 10s 268us/step - loss: 30619874.6807\n",
            "Epoch 39/200\n",
            "37758/37758 [==============================] - 10s 262us/step - loss: 30592556.7693\n",
            "Epoch 40/200\n",
            "37758/37758 [==============================] - 10s 262us/step - loss: 30565225.7792\n",
            "Epoch 41/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 30537949.4815\n",
            "Epoch 42/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 30510743.6096\n",
            "Epoch 43/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 30483449.5362\n",
            "Epoch 44/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 30456256.5620\n",
            "Epoch 45/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 30429015.1310\n",
            "Epoch 46/200\n",
            "37758/37758 [==============================] - 10s 262us/step - loss: 30401952.6568\n",
            "Epoch 47/200\n",
            "37758/37758 [==============================] - 10s 262us/step - loss: 30374867.7781\n",
            "Epoch 48/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 30347791.1872\n",
            "Epoch 49/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 30320731.4947\n",
            "Epoch 50/200\n",
            "37758/37758 [==============================] - 10s 262us/step - loss: 30293709.5321\n",
            "Epoch 51/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 30266688.2736\n",
            "Epoch 52/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 30239704.1002\n",
            "Epoch 53/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 30212758.7175\n",
            "Epoch 54/200\n",
            "37758/37758 [==============================] - 10s 262us/step - loss: 30185792.8414\n",
            "Epoch 55/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 30158910.5180\n",
            "Epoch 56/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 30132106.1893\n",
            "Epoch 57/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 30105277.7646\n",
            "Epoch 58/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 30078404.0887\n",
            "Epoch 59/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 30051681.6388\n",
            "Epoch 60/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 30024995.1918\n",
            "Epoch 61/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 29998230.9781\n",
            "Epoch 62/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 29971486.5615\n",
            "Epoch 63/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 29944801.8848\n",
            "Epoch 64/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 29918185.7354\n",
            "Epoch 65/200\n",
            "37758/37758 [==============================] - 10s 267us/step - loss: 29891539.5049\n",
            "Epoch 66/200\n",
            "37758/37758 [==============================] - 10s 270us/step - loss: 29864960.4427\n",
            "Epoch 67/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 29838449.0746\n",
            "Epoch 68/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29811949.1385\n",
            "Epoch 69/200\n",
            "37758/37758 [==============================] - 10s 265us/step - loss: 29785400.5883\n",
            "Epoch 70/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 29759007.0152\n",
            "Epoch 71/200\n",
            "37758/37758 [==============================] - 10s 262us/step - loss: 29732585.5425\n",
            "Epoch 72/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 29706214.5298\n",
            "Epoch 73/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29679785.7246\n",
            "Epoch 74/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29653495.4428\n",
            "Epoch 75/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 29627108.0893\n",
            "Epoch 76/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29600881.3200\n",
            "Epoch 77/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 29574649.3342\n",
            "Epoch 78/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 29548431.5708\n",
            "Epoch 79/200\n",
            "37758/37758 [==============================] - 10s 262us/step - loss: 29522217.6569\n",
            "Epoch 80/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29496084.5396\n",
            "Epoch 81/200\n",
            "37758/37758 [==============================] - 10s 258us/step - loss: 29469905.8271\n",
            "Epoch 82/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 29443807.7396\n",
            "Epoch 83/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29417759.8800\n",
            "Epoch 84/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29391633.8757\n",
            "Epoch 85/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 29365621.2193\n",
            "Epoch 86/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 29339580.3337\n",
            "Epoch 87/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 29313619.5822\n",
            "Epoch 88/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29287679.0546\n",
            "Epoch 89/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29261708.3742\n",
            "Epoch 90/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29235779.6119\n",
            "Epoch 91/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29209896.7152\n",
            "Epoch 92/200\n",
            "37758/37758 [==============================] - 10s 258us/step - loss: 29184139.6614\n",
            "Epoch 93/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29158258.7879\n",
            "Epoch 94/200\n",
            "37758/37758 [==============================] - 10s 258us/step - loss: 29132507.5433\n",
            "Epoch 95/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 29106788.7119\n",
            "Epoch 96/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 29081055.4143\n",
            "Epoch 97/200\n",
            "37758/37758 [==============================] - 10s 270us/step - loss: 29055287.8282\n",
            "Epoch 98/200\n",
            "37758/37758 [==============================] - 10s 263us/step - loss: 29029640.6569\n",
            "Epoch 99/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 29003956.1066\n",
            "Epoch 100/200\n",
            "37758/37758 [==============================] - 10s 264us/step - loss: 28978395.2957\n",
            "Epoch 101/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28952765.0112\n",
            "Epoch 102/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28927203.0974\n",
            "Epoch 103/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 28901728.8594\n",
            "Epoch 104/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28876162.5925\n",
            "Epoch 105/200\n",
            "37758/37758 [==============================] - 10s 258us/step - loss: 28850666.2901\n",
            "Epoch 106/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28825252.7050\n",
            "Epoch 107/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28799851.1401\n",
            "Epoch 108/200\n",
            "37758/37758 [==============================] - 10s 261us/step - loss: 28774482.0792\n",
            "Epoch 109/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28749137.8343\n",
            "Epoch 110/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28723783.2756\n",
            "Epoch 111/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 28698493.2426\n",
            "Epoch 112/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 28673223.4305\n",
            "Epoch 113/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28647931.2092\n",
            "Epoch 114/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28622642.0068\n",
            "Epoch 115/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28597423.7801\n",
            "Epoch 116/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28572291.2912\n",
            "Epoch 117/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28547172.4222\n",
            "Epoch 118/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28522084.1091\n",
            "Epoch 119/200\n",
            "37758/37758 [==============================] - 10s 260us/step - loss: 28497035.9928\n",
            "Epoch 120/200\n",
            "37758/37758 [==============================] - 10s 262us/step - loss: 28471925.0954\n",
            "Epoch 121/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28446919.5710\n",
            "Epoch 122/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28421956.1567\n",
            "Epoch 123/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28396995.3041\n",
            "Epoch 124/200\n",
            "37758/37758 [==============================] - 10s 258us/step - loss: 28371982.5275\n",
            "Epoch 125/200\n",
            "37758/37758 [==============================] - 10s 257us/step - loss: 28347109.1132\n",
            "Epoch 126/200\n",
            "37758/37758 [==============================] - 10s 257us/step - loss: 28322188.7559\n",
            "Epoch 127/200\n",
            "37758/37758 [==============================] - 10s 259us/step - loss: 28297453.8933\n",
            "Epoch 128/200\n",
            "37758/37758 [==============================] - 10s 264us/step - loss: 28272598.4616\n",
            "Epoch 129/200\n",
            "37758/37758 [==============================] - 10s 277us/step - loss: 28247758.4005\n",
            "Epoch 130/200\n",
            "37758/37758 [==============================] - 10s 268us/step - loss: 28223004.2547\n",
            "Epoch 131/200\n",
            "37758/37758 [==============================] - 10s 268us/step - loss: 28198191.5414\n",
            "Epoch 132/200\n",
            "37758/37758 [==============================] - 10s 265us/step - loss: 28173407.9018\n",
            "Epoch 133/200\n",
            "37758/37758 [==============================] - 10s 272us/step - loss: 28148796.9793\n",
            "Epoch 134/200\n",
            "37758/37758 [==============================] - 10s 274us/step - loss: 28124108.7505\n",
            "Epoch 135/200\n",
            "37758/37758 [==============================] - 10s 273us/step - loss: 28099447.8023\n",
            "Epoch 136/200\n",
            "37758/37758 [==============================] - 10s 276us/step - loss: 28074857.9804\n",
            "Epoch 137/200\n",
            "37758/37758 [==============================] - 10s 274us/step - loss: 28050305.5307\n",
            "Epoch 138/200\n",
            "37758/37758 [==============================] - 10s 270us/step - loss: 28025663.8283\n",
            "Epoch 139/200\n",
            "37758/37758 [==============================] - 10s 268us/step - loss: 28001052.7834\n",
            "Epoch 140/200\n",
            "37758/37758 [==============================] - 10s 271us/step - loss: 27976549.7247\n",
            "Epoch 141/200\n",
            "37758/37758 [==============================] - 11s 296us/step - loss: 27952046.5480\n",
            "Epoch 142/200\n",
            "37758/37758 [==============================] - 11s 292us/step - loss: 27927549.0762\n",
            "Epoch 143/200\n",
            "37758/37758 [==============================] - 11s 292us/step - loss: 27903133.1638\n",
            "Epoch 144/200\n",
            "37758/37758 [==============================] - 11s 292us/step - loss: 27878752.5254\n",
            "Epoch 145/200\n",
            "37758/37758 [==============================] - 11s 286us/step - loss: 27854414.0901\n",
            "Epoch 146/200\n",
            "37758/37758 [==============================] - 11s 287us/step - loss: 27830101.0430\n",
            "Epoch 147/200\n",
            "37758/37758 [==============================] - 11s 292us/step - loss: 27805747.3415\n",
            "Epoch 148/200\n",
            "37758/37758 [==============================] - 11s 286us/step - loss: 27781536.1703\n",
            "Epoch 149/200\n",
            "37758/37758 [==============================] - 11s 287us/step - loss: 27757259.2257\n",
            "Epoch 150/200\n",
            "37758/37758 [==============================] - 11s 287us/step - loss: 27732989.2662\n",
            "Epoch 151/200\n",
            "37758/37758 [==============================] - 11s 289us/step - loss: 27708855.0806\n",
            "Epoch 152/200\n",
            "37758/37758 [==============================] - 11s 292us/step - loss: 27684718.8710\n",
            "Epoch 153/200\n",
            "37758/37758 [==============================] - 11s 286us/step - loss: 27660546.8844\n",
            "Epoch 154/200\n",
            "37758/37758 [==============================] - 11s 289us/step - loss: 27636479.1693\n",
            "Epoch 155/200\n",
            "37758/37758 [==============================] - 11s 289us/step - loss: 27612426.5157\n",
            "Epoch 156/200\n",
            "37758/37758 [==============================] - 11s 290us/step - loss: 27588389.9192\n",
            "Epoch 157/200\n",
            "37758/37758 [==============================] - 11s 290us/step - loss: 27564383.7367\n",
            "Epoch 158/200\n",
            "37758/37758 [==============================] - 12s 309us/step - loss: 27540409.3215\n",
            "Epoch 159/200\n",
            "37758/37758 [==============================] - 11s 304us/step - loss: 27516478.0538\n",
            "Epoch 160/200\n",
            "37758/37758 [==============================] - 12s 306us/step - loss: 27492535.6281\n",
            "Epoch 161/200\n",
            "37758/37758 [==============================] - 11s 302us/step - loss: 27468671.2187\n",
            "Epoch 162/200\n",
            "37758/37758 [==============================] - 11s 300us/step - loss: 27444811.2376\n",
            "Epoch 163/200\n",
            "37758/37758 [==============================] - 11s 301us/step - loss: 27421021.0718\n",
            "Epoch 164/200\n",
            "37758/37758 [==============================] - 12s 308us/step - loss: 27397191.2198\n",
            "Epoch 165/200\n",
            "37758/37758 [==============================] - 11s 300us/step - loss: 27373479.9376\n",
            "Epoch 166/200\n",
            "37758/37758 [==============================] - 11s 299us/step - loss: 27349674.4633\n",
            "Epoch 167/200\n",
            "37758/37758 [==============================] - 11s 300us/step - loss: 27325933.2140\n",
            "Epoch 168/200\n",
            "37758/37758 [==============================] - 11s 301us/step - loss: 27302171.4209\n",
            "Epoch 169/200\n",
            "37758/37758 [==============================] - 11s 304us/step - loss: 27278456.8821\n",
            "Epoch 170/200\n",
            "37758/37758 [==============================] - 12s 306us/step - loss: 27254728.9727\n",
            "Epoch 171/200\n",
            "37758/37758 [==============================] - 11s 303us/step - loss: 27231152.1240\n",
            "Epoch 172/200\n",
            "37758/37758 [==============================] - 12s 307us/step - loss: 27207561.4168\n",
            "Epoch 173/200\n",
            "37758/37758 [==============================] - 12s 305us/step - loss: 27183923.2823\n",
            "Epoch 174/200\n",
            "37758/37758 [==============================] - 11s 303us/step - loss: 27160398.7883\n",
            "Epoch 175/200\n",
            "37758/37758 [==============================] - 11s 303us/step - loss: 27136835.9218\n",
            "Epoch 176/200\n",
            "37758/37758 [==============================] - 11s 300us/step - loss: 27113300.4652\n",
            "Epoch 177/200\n",
            "37758/37758 [==============================] - 11s 301us/step - loss: 27089907.5065\n",
            "Epoch 178/200\n",
            "37758/37758 [==============================] - 11s 300us/step - loss: 27066461.6569\n",
            "Epoch 179/200\n",
            "37758/37758 [==============================] - 11s 300us/step - loss: 27043044.4216\n",
            "Epoch 180/200\n",
            "37758/37758 [==============================] - 11s 298us/step - loss: 27019712.1702\n",
            "Epoch 181/200\n",
            "37758/37758 [==============================] - 11s 300us/step - loss: 26996424.9709\n",
            "Epoch 182/200\n",
            "37758/37758 [==============================] - 11s 294us/step - loss: 26973090.7307\n",
            "Epoch 183/200\n",
            "37758/37758 [==============================] - 11s 293us/step - loss: 26949781.0999\n",
            "Epoch 184/200\n",
            "37758/37758 [==============================] - 11s 296us/step - loss: 26926447.8704\n",
            "Epoch 185/200\n",
            "37758/37758 [==============================] - 12s 308us/step - loss: 26903251.9027\n",
            "Epoch 186/200\n",
            "37758/37758 [==============================] - 11s 295us/step - loss: 26880042.9155\n",
            "Epoch 187/200\n",
            "37758/37758 [==============================] - 11s 285us/step - loss: 26856892.4321\n",
            "Epoch 188/200\n",
            "37758/37758 [==============================] - 10s 276us/step - loss: 26833744.1484\n",
            "Epoch 189/200\n",
            "37758/37758 [==============================] - 11s 281us/step - loss: 26810639.9989\n",
            "Epoch 190/200\n",
            "37758/37758 [==============================] - 11s 280us/step - loss: 26787497.3074\n",
            "Epoch 191/200\n",
            "37758/37758 [==============================] - 11s 279us/step - loss: 26764398.3488\n",
            "Epoch 192/200\n",
            "37758/37758 [==============================] - 10s 274us/step - loss: 26741316.0943\n",
            "Epoch 193/200\n",
            "37758/37758 [==============================] - 11s 284us/step - loss: 26718310.7180\n",
            "Epoch 194/200\n",
            "37758/37758 [==============================] - 11s 286us/step - loss: 26695382.4507\n",
            "Epoch 195/200\n",
            "37758/37758 [==============================] - 10s 272us/step - loss: 26672412.3939\n",
            "Epoch 196/200\n",
            "37758/37758 [==============================] - 11s 279us/step - loss: 26649475.7809\n",
            "Epoch 197/200\n",
            "37758/37758 [==============================] - 10s 272us/step - loss: 26626621.6456\n",
            "Epoch 198/200\n",
            "37758/37758 [==============================] - 10s 270us/step - loss: 26603816.7642\n",
            "Epoch 199/200\n",
            "37758/37758 [==============================] - 10s 275us/step - loss: 26580982.3647\n",
            "Epoch 200/200\n",
            "37758/37758 [==============================] - 11s 280us/step - loss: 26558080.9654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf6e2fba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgiE7C0AFuTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "02ffd24b-a5ee-4c43-9d7a-b134c0587c94"
      },
      "source": [
        "print(model.evaluate(X,Y_obj)[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53940/53940 [==============================] - 2s 35us/step\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEWheRT2VFU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "34d7d397-987f-4395-b941-dd45c215cc20"
      },
      "source": [
        "X"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.23,  2.  ,  1.  ,  3.  , 61.5 , 55.  ],\n",
              "       [ 0.21,  3.  ,  1.  ,  2.  , 59.8 , 61.  ],\n",
              "       [ 0.23,  1.  ,  1.  ,  4.  , 56.9 , 65.  ],\n",
              "       ...,\n",
              "       [ 0.7 ,  4.  ,  0.  ,  2.  , 62.8 , 60.  ],\n",
              "       [ 0.86,  3.  ,  4.  ,  3.  , 61.  , 58.  ],\n",
              "       [ 0.75,  2.  ,  0.  ,  3.  , 62.2 , 55.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b28OMGUrV6zY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d159688d-7394-461e-a712-21893a810341"
      },
      "source": [
        "Y_obj"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 326.,  326.,  327., ..., 2757., 2757., 2757.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jTamiOLV9p3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6c58e060-b088-4bf7-bfe4-e408b6ad45a1"
      },
      "source": [
        "diamond['cut'].unique()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 1, 4, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvZLbUjsWK3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}